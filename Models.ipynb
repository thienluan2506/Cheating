{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAfblu/omC5dN4vloakIDt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xKE-R1r9aCx2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677334093123,"user_tz":-420,"elapsed":34496,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"08082352-4f5e-46f6-be6c-d0dc80a86700"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/YOLOv7_pose/yolov7-pose-estimation"],"metadata":{"id":"RvqulYgxLUod","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677334104149,"user_tz":-420,"elapsed":615,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"636e0e57-436c-48b9-82b3-26436f40ea14"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/YOLOv7_pose/yolov7-pose-estimation\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn import tree, svm\n","from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from xgboost import XGBClassifier"],"metadata":{"id":"pOOwZk-Xaa30","executionInfo":{"status":"ok","timestamp":1677334106681,"user_tz":-420,"elapsed":1930,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"test.csv\")"],"metadata":{"id":"9bNqwJL0ap53","executionInfo":{"status":"ok","timestamp":1677334107784,"user_tz":-420,"elapsed":1107,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["columnName = []\n","for i in range(17):\n","  columnName.append(\"kp\" + str(i) + \"_X\")\n","  columnName.append(\"kp\" + str(i) + \"_Y\")\n","  columnName.append(\"kp\" + str(i) + \"_Confi\")"],"metadata":{"id":"iVOq5kQwawJe","executionInfo":{"status":"ok","timestamp":1677334107785,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_cheating = df[df['label'] == 'Cheating']\n","df_noncheating = df[df['label'] == 'Non-Cheating']"],"metadata":{"id":"5VFwS9f-UEKM","executionInfo":{"status":"ok","timestamp":1677334109147,"user_tz":-420,"elapsed":12,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df_cheating"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"rOldF4G2UNyy","executionInfo":{"status":"ok","timestamp":1677334111719,"user_tz":-420,"elapsed":515,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"83b19db2-66c5-430c-94c2-41d58b394f4e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         kp0_X     kp0_Y  kp0_Confi     kp1_X     kp1_Y  kp1_Confi     kp2_X  \\\n","1506  0.617659  0.839054   0.863150  0.684358  0.875559   0.844554  0.563378   \n","1507  0.618699  0.840609   0.875331  0.684703  0.878015   0.855298  0.564693   \n","1508  0.622940  0.843531   0.846056  0.687709  0.880058   0.815234  0.569388   \n","1509  0.620980  0.836386   0.881042  0.687272  0.873766   0.862819  0.566025   \n","1510  0.619537  0.838653   0.887448  0.685610  0.876426   0.871103  0.564638   \n","...        ...       ...        ...       ...       ...        ...       ...   \n","6540  0.889130  0.945496   0.671690  0.000000  0.000000   0.000000  0.875501   \n","6541  0.893549  0.945435   0.662186  0.000000  0.000000   0.000000  0.880798   \n","6542  0.878806  0.945432   0.662122  0.000000  0.000000   0.000000  0.866325   \n","6543  0.870278  0.945342   0.687786  0.000000  0.000000   0.000000  0.856420   \n","6544  0.873590  0.945128   0.681322  0.000000  0.000000   0.000000  0.860044   \n","\n","         kp2_Y  kp2_Confi     kp3_X  ...  kp14_X    kp14_Y  kp14_Confi  \\\n","1506  0.886501   0.764939  0.798646  ...     0.0  0.013405    0.792924   \n","1507  0.888477   0.785752  0.796680  ...     0.0  0.008516    0.796468   \n","1508  0.889436   0.746726  0.797397  ...     0.0  0.023587    0.795436   \n","1509  0.883769   0.797772  0.798552  ...     0.0  0.011816    0.787432   \n","1510  0.886251   0.806280  0.797854  ...     0.0  0.019424    0.794113   \n","...        ...        ...       ...  ...     ...       ...         ...   \n","6540  1.000000   0.842320  0.000000  ...     0.0  0.000000    0.000000   \n","6541  1.000000   0.836872  0.000000  ...     0.0  0.000000    0.000000   \n","6542  1.000000   0.834942  0.000000  ...     0.0  0.000000    0.000000   \n","6543  1.000000   0.851621  0.000000  ...     0.0  0.000000    0.000000   \n","6544  1.000000   0.846311  0.000000  ...     0.0  0.000000    0.000000   \n","\n","      kp15_X  kp15_Y  kp15_Confi  kp16_X  kp16_Y  kp16_Confi     label  \n","1506     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","1507     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","1508     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","1509     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","1510     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","...      ...     ...         ...     ...     ...         ...       ...  \n","6540     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","6541     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","6542     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","6543     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","6544     0.0     0.0         0.0     0.0     0.0         0.0  Cheating  \n","\n","[3537 rows x 52 columns]"],"text/html":["\n","  <div id=\"df-c0e11991-fe4e-44a7-9fc1-dc004e141590\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kp0_X</th>\n","      <th>kp0_Y</th>\n","      <th>kp0_Confi</th>\n","      <th>kp1_X</th>\n","      <th>kp1_Y</th>\n","      <th>kp1_Confi</th>\n","      <th>kp2_X</th>\n","      <th>kp2_Y</th>\n","      <th>kp2_Confi</th>\n","      <th>kp3_X</th>\n","      <th>...</th>\n","      <th>kp14_X</th>\n","      <th>kp14_Y</th>\n","      <th>kp14_Confi</th>\n","      <th>kp15_X</th>\n","      <th>kp15_Y</th>\n","      <th>kp15_Confi</th>\n","      <th>kp16_X</th>\n","      <th>kp16_Y</th>\n","      <th>kp16_Confi</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1506</th>\n","      <td>0.617659</td>\n","      <td>0.839054</td>\n","      <td>0.863150</td>\n","      <td>0.684358</td>\n","      <td>0.875559</td>\n","      <td>0.844554</td>\n","      <td>0.563378</td>\n","      <td>0.886501</td>\n","      <td>0.764939</td>\n","      <td>0.798646</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.013405</td>\n","      <td>0.792924</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>1507</th>\n","      <td>0.618699</td>\n","      <td>0.840609</td>\n","      <td>0.875331</td>\n","      <td>0.684703</td>\n","      <td>0.878015</td>\n","      <td>0.855298</td>\n","      <td>0.564693</td>\n","      <td>0.888477</td>\n","      <td>0.785752</td>\n","      <td>0.796680</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.008516</td>\n","      <td>0.796468</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>1508</th>\n","      <td>0.622940</td>\n","      <td>0.843531</td>\n","      <td>0.846056</td>\n","      <td>0.687709</td>\n","      <td>0.880058</td>\n","      <td>0.815234</td>\n","      <td>0.569388</td>\n","      <td>0.889436</td>\n","      <td>0.746726</td>\n","      <td>0.797397</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.023587</td>\n","      <td>0.795436</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>1509</th>\n","      <td>0.620980</td>\n","      <td>0.836386</td>\n","      <td>0.881042</td>\n","      <td>0.687272</td>\n","      <td>0.873766</td>\n","      <td>0.862819</td>\n","      <td>0.566025</td>\n","      <td>0.883769</td>\n","      <td>0.797772</td>\n","      <td>0.798552</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.011816</td>\n","      <td>0.787432</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>1510</th>\n","      <td>0.619537</td>\n","      <td>0.838653</td>\n","      <td>0.887448</td>\n","      <td>0.685610</td>\n","      <td>0.876426</td>\n","      <td>0.871103</td>\n","      <td>0.564638</td>\n","      <td>0.886251</td>\n","      <td>0.806280</td>\n","      <td>0.797854</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.019424</td>\n","      <td>0.794113</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6540</th>\n","      <td>0.889130</td>\n","      <td>0.945496</td>\n","      <td>0.671690</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.875501</td>\n","      <td>1.000000</td>\n","      <td>0.842320</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>6541</th>\n","      <td>0.893549</td>\n","      <td>0.945435</td>\n","      <td>0.662186</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.880798</td>\n","      <td>1.000000</td>\n","      <td>0.836872</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>6542</th>\n","      <td>0.878806</td>\n","      <td>0.945432</td>\n","      <td>0.662122</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.866325</td>\n","      <td>1.000000</td>\n","      <td>0.834942</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>6543</th>\n","      <td>0.870278</td>\n","      <td>0.945342</td>\n","      <td>0.687786</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.856420</td>\n","      <td>1.000000</td>\n","      <td>0.851621</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>6544</th>\n","      <td>0.873590</td>\n","      <td>0.945128</td>\n","      <td>0.681322</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.860044</td>\n","      <td>1.000000</td>\n","      <td>0.846311</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>Cheating</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3537 rows × 52 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0e11991-fe4e-44a7-9fc1-dc004e141590')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c0e11991-fe4e-44a7-9fc1-dc004e141590 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c0e11991-fe4e-44a7-9fc1-dc004e141590');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df_noncheating"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"zalWR9lcUOb7","executionInfo":{"status":"ok","timestamp":1677334113663,"user_tz":-420,"elapsed":10,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"24dbc166-dde2-4698-a84b-a074cd0ffa91"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["         kp0_X     kp0_Y  kp0_Confi     kp1_X     kp1_Y  kp1_Confi     kp2_X  \\\n","0     0.627783  0.856736   0.923219  0.702739  0.880992   0.897338  0.575966   \n","1     0.630523  0.858777   0.909266  0.703706  0.883392   0.874186  0.579122   \n","2     0.628696  0.858738   0.928549  0.702393  0.883721   0.903198  0.576931   \n","3     0.625742  0.857248   0.931711  0.699985  0.882158   0.912199  0.572713   \n","4     0.626030  0.857502   0.921093  0.699691  0.882271   0.895631  0.573013   \n","...        ...       ...        ...       ...       ...        ...       ...   \n","5936  0.409495  0.858140   0.891660  0.479993  0.895990   0.927850  0.342490   \n","5937  0.408809  0.858281   0.889903  0.477956  0.896134   0.925658  0.342450   \n","5938  0.411675  0.859023   0.878882  0.481305  0.896417   0.915483  0.345015   \n","5939  0.407110  0.859503   0.875994  0.477513  0.896373   0.915189  0.341427   \n","5940  0.407706  0.858507   0.871496  0.477839  0.895979   0.913907  0.341807   \n","\n","         kp2_Y  kp2_Confi     kp3_X  ...    kp14_X    kp14_Y  kp14_Confi  \\\n","0     0.895504   0.880142  0.823285  ...  0.000000  0.304594    0.866050   \n","1     0.896659   0.861140  0.820322  ...  0.000000  0.304502    0.865908   \n","2     0.897197   0.889852  0.820132  ...  0.000000  0.307547    0.863121   \n","3     0.895703   0.892731  0.820457  ...  0.000000  0.303982    0.866609   \n","4     0.895215   0.878399  0.817954  ...  0.000000  0.300596    0.867966   \n","...        ...        ...       ...  ...       ...       ...         ...   \n","5936  0.902327   0.786151  0.647598  ...  0.118642  0.243210    0.887838   \n","5937  0.902025   0.779671  0.645722  ...  0.106124  0.242601    0.887305   \n","5938  0.902216   0.757801  0.649042  ...  0.106038  0.257244    0.898706   \n","5939  0.903685   0.754751  0.648741  ...  0.134676  0.246024    0.899425   \n","5940  0.902715   0.749224  0.649643  ...  0.123711  0.243479    0.888618   \n","\n","        kp15_X    kp15_Y  kp15_Confi    kp16_X    kp16_Y  kp16_Confi  \\\n","0     0.668223  0.052104    0.500082  0.053231  0.000000    0.514520   \n","1     0.000000  0.000000    0.000000  0.054519  0.000000    0.511976   \n","2     0.000000  0.000000    0.000000  0.051829  0.000000    0.503234   \n","3     0.000000  0.000000    0.000000  0.053558  0.000000    0.510904   \n","4     0.000000  0.000000    0.000000  0.051245  0.000000    0.512254   \n","...        ...       ...         ...       ...       ...         ...   \n","5936  0.790974  0.000000    0.686193  0.404293  0.039333    0.687370   \n","5937  0.793491  0.000000    0.687415  0.405893  0.038556    0.688159   \n","5938  0.791096  0.000000    0.719262  0.393406  0.051535    0.719531   \n","5939  0.793454  0.000000    0.723523  0.421999  0.043532    0.724942   \n","5940  0.790623  0.000000    0.695031  0.435043  0.045211    0.696006   \n","\n","             label  \n","0     Non-Cheating  \n","1     Non-Cheating  \n","2     Non-Cheating  \n","3     Non-Cheating  \n","4     Non-Cheating  \n","...            ...  \n","5936  Non-Cheating  \n","5937  Non-Cheating  \n","5938  Non-Cheating  \n","5939  Non-Cheating  \n","5940  Non-Cheating  \n","\n","[3008 rows x 52 columns]"],"text/html":["\n","  <div id=\"df-4b2caf98-e4be-4b6d-949b-e0008c7ccc28\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>kp0_X</th>\n","      <th>kp0_Y</th>\n","      <th>kp0_Confi</th>\n","      <th>kp1_X</th>\n","      <th>kp1_Y</th>\n","      <th>kp1_Confi</th>\n","      <th>kp2_X</th>\n","      <th>kp2_Y</th>\n","      <th>kp2_Confi</th>\n","      <th>kp3_X</th>\n","      <th>...</th>\n","      <th>kp14_X</th>\n","      <th>kp14_Y</th>\n","      <th>kp14_Confi</th>\n","      <th>kp15_X</th>\n","      <th>kp15_Y</th>\n","      <th>kp15_Confi</th>\n","      <th>kp16_X</th>\n","      <th>kp16_Y</th>\n","      <th>kp16_Confi</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.627783</td>\n","      <td>0.856736</td>\n","      <td>0.923219</td>\n","      <td>0.702739</td>\n","      <td>0.880992</td>\n","      <td>0.897338</td>\n","      <td>0.575966</td>\n","      <td>0.895504</td>\n","      <td>0.880142</td>\n","      <td>0.823285</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.304594</td>\n","      <td>0.866050</td>\n","      <td>0.668223</td>\n","      <td>0.052104</td>\n","      <td>0.500082</td>\n","      <td>0.053231</td>\n","      <td>0.000000</td>\n","      <td>0.514520</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.630523</td>\n","      <td>0.858777</td>\n","      <td>0.909266</td>\n","      <td>0.703706</td>\n","      <td>0.883392</td>\n","      <td>0.874186</td>\n","      <td>0.579122</td>\n","      <td>0.896659</td>\n","      <td>0.861140</td>\n","      <td>0.820322</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.304502</td>\n","      <td>0.865908</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.054519</td>\n","      <td>0.000000</td>\n","      <td>0.511976</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.628696</td>\n","      <td>0.858738</td>\n","      <td>0.928549</td>\n","      <td>0.702393</td>\n","      <td>0.883721</td>\n","      <td>0.903198</td>\n","      <td>0.576931</td>\n","      <td>0.897197</td>\n","      <td>0.889852</td>\n","      <td>0.820132</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.307547</td>\n","      <td>0.863121</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.051829</td>\n","      <td>0.000000</td>\n","      <td>0.503234</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.625742</td>\n","      <td>0.857248</td>\n","      <td>0.931711</td>\n","      <td>0.699985</td>\n","      <td>0.882158</td>\n","      <td>0.912199</td>\n","      <td>0.572713</td>\n","      <td>0.895703</td>\n","      <td>0.892731</td>\n","      <td>0.820457</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.303982</td>\n","      <td>0.866609</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.053558</td>\n","      <td>0.000000</td>\n","      <td>0.510904</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.626030</td>\n","      <td>0.857502</td>\n","      <td>0.921093</td>\n","      <td>0.699691</td>\n","      <td>0.882271</td>\n","      <td>0.895631</td>\n","      <td>0.573013</td>\n","      <td>0.895215</td>\n","      <td>0.878399</td>\n","      <td>0.817954</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.300596</td>\n","      <td>0.867966</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.051245</td>\n","      <td>0.000000</td>\n","      <td>0.512254</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5936</th>\n","      <td>0.409495</td>\n","      <td>0.858140</td>\n","      <td>0.891660</td>\n","      <td>0.479993</td>\n","      <td>0.895990</td>\n","      <td>0.927850</td>\n","      <td>0.342490</td>\n","      <td>0.902327</td>\n","      <td>0.786151</td>\n","      <td>0.647598</td>\n","      <td>...</td>\n","      <td>0.118642</td>\n","      <td>0.243210</td>\n","      <td>0.887838</td>\n","      <td>0.790974</td>\n","      <td>0.000000</td>\n","      <td>0.686193</td>\n","      <td>0.404293</td>\n","      <td>0.039333</td>\n","      <td>0.687370</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>5937</th>\n","      <td>0.408809</td>\n","      <td>0.858281</td>\n","      <td>0.889903</td>\n","      <td>0.477956</td>\n","      <td>0.896134</td>\n","      <td>0.925658</td>\n","      <td>0.342450</td>\n","      <td>0.902025</td>\n","      <td>0.779671</td>\n","      <td>0.645722</td>\n","      <td>...</td>\n","      <td>0.106124</td>\n","      <td>0.242601</td>\n","      <td>0.887305</td>\n","      <td>0.793491</td>\n","      <td>0.000000</td>\n","      <td>0.687415</td>\n","      <td>0.405893</td>\n","      <td>0.038556</td>\n","      <td>0.688159</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>5938</th>\n","      <td>0.411675</td>\n","      <td>0.859023</td>\n","      <td>0.878882</td>\n","      <td>0.481305</td>\n","      <td>0.896417</td>\n","      <td>0.915483</td>\n","      <td>0.345015</td>\n","      <td>0.902216</td>\n","      <td>0.757801</td>\n","      <td>0.649042</td>\n","      <td>...</td>\n","      <td>0.106038</td>\n","      <td>0.257244</td>\n","      <td>0.898706</td>\n","      <td>0.791096</td>\n","      <td>0.000000</td>\n","      <td>0.719262</td>\n","      <td>0.393406</td>\n","      <td>0.051535</td>\n","      <td>0.719531</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>5939</th>\n","      <td>0.407110</td>\n","      <td>0.859503</td>\n","      <td>0.875994</td>\n","      <td>0.477513</td>\n","      <td>0.896373</td>\n","      <td>0.915189</td>\n","      <td>0.341427</td>\n","      <td>0.903685</td>\n","      <td>0.754751</td>\n","      <td>0.648741</td>\n","      <td>...</td>\n","      <td>0.134676</td>\n","      <td>0.246024</td>\n","      <td>0.899425</td>\n","      <td>0.793454</td>\n","      <td>0.000000</td>\n","      <td>0.723523</td>\n","      <td>0.421999</td>\n","      <td>0.043532</td>\n","      <td>0.724942</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","    <tr>\n","      <th>5940</th>\n","      <td>0.407706</td>\n","      <td>0.858507</td>\n","      <td>0.871496</td>\n","      <td>0.477839</td>\n","      <td>0.895979</td>\n","      <td>0.913907</td>\n","      <td>0.341807</td>\n","      <td>0.902715</td>\n","      <td>0.749224</td>\n","      <td>0.649643</td>\n","      <td>...</td>\n","      <td>0.123711</td>\n","      <td>0.243479</td>\n","      <td>0.888618</td>\n","      <td>0.790623</td>\n","      <td>0.000000</td>\n","      <td>0.695031</td>\n","      <td>0.435043</td>\n","      <td>0.045211</td>\n","      <td>0.696006</td>\n","      <td>Non-Cheating</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3008 rows × 52 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b2caf98-e4be-4b6d-949b-e0008c7ccc28')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4b2caf98-e4be-4b6d-949b-e0008c7ccc28 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4b2caf98-e4be-4b6d-949b-e0008c7ccc28');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["input shape(num_shape, num_frame\"num_time_step\", num_joints,num_demention)= (1000,10,17,3)"],"metadata":{"id":"bMKbjUcjGkgj"}},{"cell_type":"code","source":["no_of_timesteps = 10\n","num_joints = 17\n","num_demention = 3\n","n_sample = len(df_cheating)\n","df_cheating = np.resize(df_cheating[columnName],(int(n_sample/no_of_timesteps), no_of_timesteps, num_joints, num_demention))\n","\n","n_sample = len(df_noncheating)\n","df_noncheating = np.resize(df_noncheating[columnName],(int(n_sample/no_of_timesteps), no_of_timesteps, num_joints, num_demention))\n","\n","print(df_cheating)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71FKTsJmUbGJ","executionInfo":{"status":"ok","timestamp":1677334164574,"user_tz":-420,"elapsed":507,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"d8206e12-1c0e-47bc-997c-db52de4374c3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[[0.61765935 0.83905355 0.8631503 ]\n","   [0.6843577  0.87555885 0.84455442]\n","   [0.56337843 0.88650052 0.76493919]\n","   ...\n","   [0.         0.01340521 0.7929244 ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.61869927 0.84060884 0.87533104]\n","   [0.68470312 0.87801517 0.85529798]\n","   [0.56469347 0.88847709 0.785752  ]\n","   ...\n","   [0.         0.0085162  0.79646838]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62293992 0.84353055 0.8460564 ]\n","   [0.68770865 0.8800584  0.81523371]\n","   [0.56938764 0.88943575 0.74672621]\n","   ...\n","   [0.         0.02358732 0.79543608]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.6291872  0.83906959 0.85043168]\n","   [0.69237352 0.87791573 0.8217777 ]\n","   [0.57453781 0.88531164 0.75591403]\n","   ...\n","   [0.         0.0011572  0.78311741]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62093054 0.83630226 0.85406137]\n","   [0.6859022  0.87370827 0.83807081]\n","   [0.56664384 0.88317421 0.75494015]\n","   ...\n","   [0.         0.01363695 0.78959638]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62236512 0.83767304 0.85614777]\n","   [0.6873521  0.87526528 0.84299195]\n","   [0.56726192 0.88422793 0.75410539]\n","   ...\n","   [0.         0.00720909 0.78834772]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]\n","\n","\n"," [[[0.62749353 0.83878269 0.85229266]\n","   [0.69246433 0.87685119 0.82321697]\n","   [0.57138853 0.8844448  0.75719571]\n","   ...\n","   [0.         0.01260074 0.79169285]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.63273546 0.83834726 0.8746351 ]\n","   [0.69745337 0.87774752 0.84676623]\n","   [0.57506506 0.88374066 0.7931124 ]\n","   ...\n","   [0.         0.00748408 0.79331934]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62943014 0.83259899 0.86564445]\n","   [0.69460359 0.87135611 0.83582956]\n","   [0.57260978 0.87880206 0.77790111]\n","   ...\n","   [0.         0.         0.78339493]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.61635123 0.83041323 0.86907756]\n","   [0.68149001 0.86548472 0.84895605]\n","   [0.56375536 0.87791455 0.77373725]\n","   ...\n","   [0.         0.00846941 0.80458057]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.61691693 0.82991607 0.88245386]\n","   [0.68258433 0.86518858 0.86355919]\n","   [0.56484644 0.87795378 0.79747403]\n","   ...\n","   [0.         0.01396332 0.80562884]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.61815015 0.82900876 0.87285584]\n","   [0.68381203 0.86488384 0.84925979]\n","   [0.56536461 0.87686608 0.78378743]\n","   ...\n","   [0.         0.01261063 0.80613303]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]\n","\n","\n"," [[[0.61742986 0.82424557 0.89676261]\n","   [0.68412183 0.86106465 0.87416464]\n","   [0.56407282 0.87381611 0.81938642]\n","   ...\n","   [0.         0.00523173 0.80408716]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62441389 0.83399348 0.85173893]\n","   [0.68809777 0.86933413 0.81889987]\n","   [0.57194682 0.87975617 0.75378162]\n","   ...\n","   [0.         0.00723421 0.79801565]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62158421 0.83130462 0.87823379]\n","   [0.68685522 0.86774261 0.8519935 ]\n","   [0.56827941 0.87902276 0.79315454]\n","   ...\n","   [0.         0.00117287 0.8017354 ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.63012499 0.83525905 0.87172413]\n","   [0.69533121 0.87198479 0.84353441]\n","   [0.57550026 0.88133016 0.78589141]\n","   ...\n","   [0.         0.00428719 0.80449998]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62412254 0.83248481 0.88947695]\n","   [0.69057788 0.86869239 0.87219375]\n","   [0.57021102 0.88020622 0.80658823]\n","   ...\n","   [0.         0.0032177  0.80667359]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.62268056 0.84039419 0.87712914]\n","   [0.68899805 0.87601573 0.86480618]\n","   [0.56861866 0.88666774 0.79428971]\n","   ...\n","   [0.         0.01050017 0.79740286]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]\n","\n","\n"," ...\n","\n","\n"," [[[0.89203132 0.95527252 0.5260579 ]\n","   [0.         0.         0.        ]\n","   [0.87897204 1.         0.77467161]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.86716204 1.         0.74299353]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.87458196 0.95247522 0.52192348]\n","   [0.         0.         0.        ]\n","   [0.86575856 1.         0.76291198]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.89832261 0.95164071 0.53499496]\n","   [0.         0.         0.        ]\n","   [0.88810318 1.         0.7716226 ]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.89334468 0.9493473  0.56848133]\n","   [0.         0.         0.        ]\n","   [0.88520462 1.         0.79212481]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.8951112  0.95086697 0.59260911]\n","   [0.         0.         0.        ]\n","   [0.88204608 1.         0.81057906]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]\n","\n","\n"," [[[0.89306274 0.95082139 0.60460258]\n","   [0.         0.         0.        ]\n","   [0.87934994 1.         0.81750917]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.9065748  0.94986775 0.6341731 ]\n","   [0.         0.         0.        ]\n","   [0.89306481 1.         0.83660662]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.91254408 0.94980891 0.65481192]\n","   [0.         0.         0.        ]\n","   [0.89780819 1.         0.84824753]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.92703624 0.94862208 0.67970234]\n","   [0.         0.         0.        ]\n","   [0.91038266 1.         0.86101627]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.9302097  0.94839803 0.69140303]\n","   [0.         0.         0.        ]\n","   [0.91308688 1.         0.8680926 ]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.92897613 0.94794836 0.65987504]\n","   [0.         0.         0.        ]\n","   [0.91329231 1.         0.8479138 ]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]\n","\n","\n"," [[[0.91583454 0.9473929  0.67714208]\n","   [0.         0.         0.        ]\n","   [0.90050758 1.         0.85703248]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.90989235 0.94724028 0.65894085]\n","   [0.         0.         0.        ]\n","   [0.89501251 1.         0.84548247]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.91324518 0.94726362 0.64664781]\n","   [0.         0.         0.        ]\n","   [0.89847017 1.         0.83595353]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  ...\n","\n","  [[0.88959068 0.946266   0.64683414]\n","   [0.         0.         0.        ]\n","   [0.87613109 1.         0.82899344]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.8991662  0.94616068 0.66134387]\n","   [0.         0.         0.        ]\n","   [0.88498639 1.         0.83800972]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]\n","\n","  [[0.88710644 0.94612471 0.65478408]\n","   [0.         0.         0.        ]\n","   [0.87417236 1.         0.83427286]\n","   ...\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]\n","   [0.         0.         0.        ]]]]\n"]}]},{"cell_type":"code","source":["X = np.append(df_cheating,df_noncheating , axis=0)"],"metadata":{"id":"qezaAnLv6rWs","executionInfo":{"status":"ok","timestamp":1677334333172,"user_tz":-420,"elapsed":7,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["y = []\n","print(df_cheating.shape[0])\n","print(df_noncheating.shape[0])\n","for i in range(df_cheating.shape[0]):\n","  y.append(0)\n","for i in range(df_noncheating.shape[0]):\n","  y.append(1)\n","y = np.array(y)\n","print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f19cLtah6Xnq","executionInfo":{"status":"ok","timestamp":1677334407666,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"5867d7cd-2f62-4004-d19b-1b3452d43ce5"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["353\n","300\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"," 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"]}]},{"cell_type":"code","source":["print(X.shape)\n","print(y.shape)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"metadata":{"id":"EPGobZjdazL3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677334412087,"user_tz":-420,"elapsed":842,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"bb0f430a-7ba6-419b-908a-d8edaff7a1a7"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["(653, 10, 17, 3)\n","(653,)\n"]}]},{"cell_type":"markdown","source":["Train SVM"],"metadata":{"id":"qgiTKqNxfFH_"}},{"cell_type":"code","source":["model = svm.LinearSVC()\n","model.fit(X_train, y_train)\n","prediction = model.predict(X_test)"],"metadata":{"id":"6UxT7Ag5fLVx","colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"status":"error","timestamp":1677334430254,"user_tz":-420,"elapsed":517,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"5b83beba-b210-4722-ac8c-482fd146529b"},"execution_count":16,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c382480939ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Penalty term must be positive; got (C=%r)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    792\u001b[0m                 ) from e\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."]}]},{"cell_type":"code","source":["print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")\n","print(f\"calssification report {classification_report(y_test, prediction)}\")"],"metadata":{"id":"fri7Cf2qf-mv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train Decision Tree"],"metadata":{"id":"OyuYMDSTfNK0"}},{"cell_type":"code","source":["model = tree.DecisionTreeClassifier()\n","model =  model.fit(X_train, y_train)\n","prediction =  model.predict(X_test)\n"],"metadata":{"id":"N56cCYeXdoLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Test Set Accuracy : {accuracy_score(y_test, prediction) * 100} %\\n\\n\")\n","print(f\"calssification report {classification_report(y_test, prediction)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjucm1xaezFm","executionInfo":{"status":"ok","timestamp":1675414459136,"user_tz":-420,"elapsed":9,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"cbd92de4-d02f-4d86-b67b-eb2c1de11660"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Set Accuracy : 98.5485103132162 %\n","\n","\n","calssification report               precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.99       725\n","           1       0.98      0.99      0.98       584\n","\n","    accuracy                           0.99      1309\n","   macro avg       0.98      0.99      0.99      1309\n","weighted avg       0.99      0.99      0.99      1309\n","\n"]}]},{"cell_type":"markdown","source":["Train Ramdom Forest"],"metadata":{"id":"pcTZExURfkff"}},{"cell_type":"code","source":["model = XGBClassifier()\n","model.fit(X_train, y_train)\n","preds = model.predict(X_test)\n","score = mean_absolute_error(preds, y_test)\n","acc = accuracy_score(preds, y_test)\n","print(score)\n","print(acc)"],"metadata":{"id":"x8QlScC_fjlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numrandom1 = np.random.uniform(-0.05, 0.05)\n","numrandom2 = np.random.uniform(-0.05, 0.05)\n","print(numrandom1)\n","print(numrandom2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvNeRzXILOvN","executionInfo":{"status":"ok","timestamp":1675513218313,"user_tz":-420,"elapsed":772,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"e8e46689-970d-4a6a-ecbf-ec59b505da2d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.001663069222455127\n","-0.04128283361534647\n"]}]},{"cell_type":"markdown","source":["Model LSTM"],"metadata":{"id":"Omb8mkKC8ils"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import keras \n","from keras.layers import LSTM, Dense,Dropout, \n","from keras.models import Sequential\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"id":"Or2iteiD9JNC","executionInfo":{"status":"error","timestamp":1677338812501,"user_tz":-420,"elapsed":1448,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"0e5a3016-bc22-4eab-fffd-a596ba3b84ab"},"execution_count":80,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-80-67bc084c8d6f>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from keras.layers import LSTM, Dense,Dropout,\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"]}]},{"cell_type":"code","source":["print(X.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GiR36wbN_ty2","executionInfo":{"status":"ok","timestamp":1677335656993,"user_tz":-420,"elapsed":3,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"61fed50f-24f3-4789-c264-7f26a678a007"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["(653, 10, 17, 3)\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"],"metadata":{"id":"BWDfQO74CLo_","executionInfo":{"status":"ok","timestamp":1677336300000,"user_tz":-420,"elapsed":976,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uz2EOb8-CIgd","executionInfo":{"status":"ok","timestamp":1677336309734,"user_tz":-420,"elapsed":4,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"1a0171ee-4ce1-4e5f-d9bb-fe91d2b13ac1"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["(522, 10, 17, 3)\n"]}]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n","model = Sequential()\n","\n","model.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[2], X.shape[3])))\n","model.add(Dropout(0.2))\n","\n","\n","\n","model.add(Dense(units = 1, activation=\"sigmoid\"))\n","model.compile(optimizer=\"adam\", metrics = ['accuracy'], loss = \"binary_crossentropy\")\n","model.summary()\n","# model.fit(X_train, y_train, epochs=20, batch_size=32,validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-5hVTlh_bE8","executionInfo":{"status":"ok","timestamp":1677338219067,"user_tz":-420,"elapsed":26,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"6cc15966-445f-4388-d9e9-f302536e767e"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_34\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_78 (LSTM)              (None, 17, 50)            10800     \n","                                                                 \n"," dropout_59 (Dropout)        (None, 17, 50)            0         \n","                                                                 \n"," dense_15 (Dense)            (None, 17, 1)             51        \n","                                                                 \n","=================================================================\n","Total params: 10,851\n","Trainable params: 10,851\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","model  = Sequential()\n","model.add(LSTM(units = 50, return_sequences = True, input_shape = (X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units = 50, return_sequences = True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units = 50, return_sequences = True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(units = 50))\n","model.add(Dropout(0.2))\n","model.add(Dense(units = 1, activation=\"sigmoid\"))\n","model.summary()\n","\n","# model.fit(X_train, y_train, epochs=20, batch_size=32,validation_data=(X_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5ijP-tm8iSb","executionInfo":{"status":"ok","timestamp":1677336447457,"user_tz":-420,"elapsed":1681,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"e5f05f12-beef-4d5f-e34e-16e34403ab65"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_24 (LSTM)              (None, 10, 50)            13600     \n","                                                                 \n"," dropout_16 (Dropout)        (None, 10, 50)            0         \n","                                                                 \n"," lstm_25 (LSTM)              (None, 10, 50)            20200     \n","                                                                 \n"," dropout_17 (Dropout)        (None, 10, 50)            0         \n","                                                                 \n"," lstm_26 (LSTM)              (None, 10, 50)            20200     \n","                                                                 \n"," dropout_18 (Dropout)        (None, 10, 50)            0         \n","                                                                 \n"," lstm_27 (LSTM)              (None, 50)                20200     \n","                                                                 \n"," dropout_19 (Dropout)        (None, 50)                0         \n","                                                                 \n"," dense_6 (Dense)             (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 74,251\n","Trainable params: 74,251\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Model ConvLSTM"],"metadata":{"id":"L6WEqenRickX"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(ConvLSTM2D(filters=64, kernel_size=(7, 7),\n","                     input_shape=(None, 101, 101, 1), padding='same',  return_sequences=True, \n","                     activation='tanh', recurrent_activation='hard_sigmoid',\n","                     kernel_initializer='glorot_uniform', unit_forget_bias=True, \n","                     dropout=0.3, recurrent_dropout=0.3, go_backwards=True ))\n","model.add(BatchNormalization())\n","\n","model.add(ConvLSTM2D(filters=32, kernel_size=(7, 7), padding='same', return_sequences=True, \n","                     activation='tanh', recurrent_activation='hard_sigmoid', \n","                     kernel_initializer='glorot_uniform', unit_forget_bias=True, \n","                     dropout=0.4, recurrent_dropout=0.3, go_backwards=True ))\n","model.add(BatchNormalization())\n","\n","model.add(ConvLSTM2D(filters=32, kernel_size=(7, 7), padding='same', return_sequences=True, \n","                     activation='tanh', recurrent_activation='hard_sigmoid', \n","                     kernel_initializer='glorot_uniform', unit_forget_bias=True, \n","                     dropout=0.4, recurrent_dropout=0.3, go_backwards=True ))\n","model.add(BatchNormalization())\n","\n","\n","model.add(ConvLSTM2D(filters=32, kernel_size=(7, 7), padding='same', return_sequences=False, \n","                     activation='tanh', recurrent_activation='hard_sigmoid', \n","                     kernel_initializer='glorot_uniform', unit_forget_bias=True, \n","                     dropout=0.4, recurrent_dropout=0.3, go_backwards=True ))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters=1, kernel_size=(1, 1),\n","               activation='sigmoid',\n","               padding='same', data_format='channels_last')) \n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d9SUeTuTL64N","executionInfo":{"status":"ok","timestamp":1677338862387,"user_tz":-420,"elapsed":2972,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"24c900b6-3f14-49a5-9d37-9b2ff1fd40cc"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_43\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_lstm2d_17 (ConvLSTM2D)  (None, None, 101, 101, 6  815616   \n","                             4)                                  \n","                                                                 \n"," batch_normalization_3 (Batc  (None, None, 101, 101, 6  256      \n"," hNormalization)             4)                                  \n","                                                                 \n"," conv_lstm2d_18 (ConvLSTM2D)  (None, None, 101, 101, 3  602240   \n","                             2)                                  \n","                                                                 \n"," batch_normalization_4 (Batc  (None, None, 101, 101, 3  128      \n"," hNormalization)             2)                                  \n","                                                                 \n"," conv_lstm2d_19 (ConvLSTM2D)  (None, None, 101, 101, 3  401536   \n","                             2)                                  \n","                                                                 \n"," batch_normalization_5 (Batc  (None, None, 101, 101, 3  128      \n"," hNormalization)             2)                                  \n","                                                                 \n"," conv_lstm2d_20 (ConvLSTM2D)  (None, 101, 101, 32)     401536    \n","                                                                 \n"," batch_normalization_6 (Batc  (None, 101, 101, 32)     128       \n"," hNormalization)                                                 \n","                                                                 \n"," conv2d (Conv2D)             (None, 101, 101, 1)       33        \n","                                                                 \n","=================================================================\n","Total params: 2,221,601\n","Trainable params: 2,221,281\n","Non-trainable params: 320\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3),\n","                     input_shape=(None, 10, 17, 3), padding='same',  return_sequences=True))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kK6WNd33IZjZ","executionInfo":{"status":"ok","timestamp":1677338998161,"user_tz":-420,"elapsed":807,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"666aa7d0-cca0-44a1-c068-d66b6084b303"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_47\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv_lstm2d_24 (ConvLSTM2D)  (None, None, 10, 17, 64)  154624   \n","                                                                 \n","=================================================================\n","Total params: 154,624\n","Trainable params: 154,624\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Input, ConvLSTM2D, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.models import Model\n","\n","#Define the input shape\n","input_shape =(10, 17, 3) # (None, num_frames, num_joinys, num_dimensions) \n","\n","input_layer = Input(shape = input_shape)\n","\n","conv_lstm_layer1 = ConvLSTM2D(filters=16, kernel_size = (3,3), padding ='same', return_sequences = True)(input_layer)\n","conv_lstm_layer1 = BatchNormalization()(conv_lstm_layer1)\n","\n","conv_lstm_layer2 = ConvLSTM2D(filters = 32, kernel_size = (3,3), padding ='same', return_sequences = False)(conv_lstm_layer1)\n","conv_lstm_layer2 = BatchNormalization()(conv_lstm_layer2)\n","\n","flatten_layer = Flatten()(conv_lstm_layer2)\n","dense_layer = Dense(units = 256, activation ='relu')(flatten_layer)\n","output_layer = Dense(units = 1, activation ='sigmoid')\n","\n","model = Model(inputs=input_layer, outputs=output_layer)\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()\n","# model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"UWJQgn7wib98","executionInfo":{"status":"error","timestamp":1677337921847,"user_tz":-420,"elapsed":5,"user":{"displayName":"Minh Nguyen","userId":"06082769105162599484"}},"outputId":"185cf4aa-973b-4d96-b638-a6d3ecd95879"},"execution_count":67,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-67-f0410a2f6e09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconv_lstm_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvLSTM2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mconv_lstm_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_lstm_layer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/layers/rnn/base_rnn.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                     \u001b[0;34m\"is incompatible with the layer: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv_lstm2d_8\" is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: (None, 10, 17, 3)"]}]}]}